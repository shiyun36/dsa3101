{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c71b38a7-2950-4936-9ffa-025243c15b21",
   "metadata": {},
   "source": [
    "# Automated data retrieval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1fd5e659-63fd-4355-a5ad-b5c38160fcf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import ocrmypdf\n",
    "from PyPDF2 import PdfReader\n",
    "import re\n",
    "import json\n",
    "import fitz  # PyMuPDF for PDF extraction\n",
    "import chromadb  # Vector Database\n",
    "from tqdm import tqdm\n",
    "import logging\n",
    "import requests\n",
    "import time\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch \n",
    "from torch import nn\\]\n",
    "from torch.optim import AdamW  \n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import numpy as np\n",
    "import pandas as pd \n",
    "from io import BytesIO\n",
    "from transformers import AutoModelForSequenceClassification, AutoModelForCausalLM, AutoTokenizer, pipeline, BertTokenizer, BertModel, Trainer, TrainingArguments\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import spacy\n",
    "from spacy import displacy\n",
    "torch.set_default_device(\"cpu\")\n",
    "import random\n",
    "import json\n",
    "from google import genai\n",
    "google_api_key = \"AIzaSyCutzQsZEOJUQgHwcvjtPNiLFbgyxOfmko\"\n",
    "from openai import OpenAI\n",
    "API_KEY = \"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\" \n",
    "\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from googlesearch import search\n",
    "from fuzzywuzzy import fuzz "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3bee610-2d14-4f3e-9bc3-4f163c62175e",
   "metadata": {},
   "source": [
    "# Automate pulling pdfs online"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3619c33-dde8-4cda-b3ec-074c8cf2926f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "client = genai.Client(api_key=google_api_key)\n",
    "gemini_eval = client.models.generate_content(\n",
    "    model=\"gemini-2.0-flash\",\n",
    "    contents= \"Can you randomly generate a list of company names that come from different sizes, based in different countries, and of various industries. For example, companies that could be generated are [Pfizer, Apple, Uber, LVMH], etc where they are in the healthcare, technology, transport, FMCG and based in different countries\"\n",
    ")\n",
    "company_names = [name for name in re.findall(r\"\\*\\*(.+?)\\:\\*\\*\", gemini_eval.text) if \"Disclaimer\" not in name]\n",
    "company_list = company_names[:3]\n",
    "years=[2024, 2023, 2022, 2021]\n",
    "print(company_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57e2a158-070f-4add-a20b-42128b8dfec4",
   "metadata": {},
   "outputs": [],
   "source": [
    "pdf_links = []\n",
    "for company in company_list:\n",
    "    for year in years:\n",
    "        query = f\"{company} {year} ESG report filetype:pdf\"\n",
    "        \n",
    "        for url in search(query, num_results=1):\n",
    "            if url.endswith(\".pdf\"):  \n",
    "                pdf_links.append(url)\n",
    "print(pdf_links)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e79a5aed-3ddc-417f-85e7-4a3297c4bbe4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_company_and_year(pdf_url):\n",
    "    \"\"\"\n",
    "    Extracts company name and year from the PDF URL.\n",
    "    Assumes company name is right after 'https://' and the year is just before '.pdf'.\n",
    "    \"\"\"\n",
    "    match = re.search(r'https://(?:www\\.)?([a-zA-Z0-9-]+).*?(\\d{4}(?:-\\d{4})?)\\.pdf', pdf_url)\n",
    "    if match:\n",
    "        return match.group(1), match.group(2)\n",
    "    else:\n",
    "        print(f\"Failed to extract company name and year from URL: {pdf_url}\")\n",
    "        return None, None\n",
    "\n",
    "def extract_text_from_pdf(pdf_bytes):\n",
    "    \"\"\"\n",
    "    Extracts text from a PDF (after OCR is applied) and returns cleaned sentences.\n",
    "    \"\"\"\n",
    "    def clean_page_text(text):\n",
    "        \"\"\"Removes headers, footers, and page numbers from extracted text.\"\"\"\n",
    "        lines = text.split(\"\\n\")\n",
    "        if len(lines) > 2:\n",
    "            lines = lines[2:]\n",
    "        lines = [line for line in lines if not re.match(r'^(Page\\s*\\d+|\\d+|P\\.\\s*\\d+)$', line.strip(), re.IGNORECASE)]\n",
    "        return \"\\n\".join(lines)\n",
    "\n",
    "    cleaned_text = ''\n",
    "    pdfReader = PdfReader(pdf_bytes)\n",
    "    \n",
    "    for page in pdfReader.pages:\n",
    "        raw_text = page.extract_text()\n",
    "        if raw_text:\n",
    "            cleaned_text += clean_page_text(raw_text) + ' '\n",
    "\n",
    "    sentences = re.split(r'(?<=[.!?])\\s+', cleaned_text.strip())\n",
    "    final_sentences = [re.sub(r'\\s+', ' ', sentence).strip() for sentence in sentences]\n",
    "    \n",
    "    return final_sentences\n",
    "\n",
    "def process_pdf_and_extract_text(pdf_url, output_json_dir):\n",
    "    \"\"\"\n",
    "    Downloads a PDF from a URL, applies OCR, extracts text, and saves it as JSON.\n",
    "    \"\"\"\n",
    "    company_name, year = extract_company_and_year(pdf_url)\n",
    "    if not company_name or not year:\n",
    "        return\n",
    "    \n",
    "    output_json_path = os.path.join(output_json_dir, f\"{company_name}_{year}.json\")\n",
    "    \n",
    "    if os.path.exists(output_json_path):\n",
    "        print(f\"Skipping '{pdf_url}': JSON output already exists.\")\n",
    "        return\n",
    "\n",
    "    print(f\"Processing PDF for company: {company_name}, from URL: {pdf_url}\")\n",
    "\n",
    "    try:\n",
    "        response = requests.get(pdf_url)\n",
    "        response.raise_for_status()\n",
    "        pdf_data = BytesIO(response.content)  # Load PDF into memory\n",
    "\n",
    "        # Apply OCR and store the result in memory\n",
    "        ocr_pdf_data = BytesIO()\n",
    "        ocrmypdf.ocr(pdf_data, ocr_pdf_data, force_ocr=True)\n",
    "        ocr_pdf_data.seek(0)  # Reset pointer for reading\n",
    "\n",
    "        # Extract text and clean it\n",
    "        sentences = extract_text_from_pdf(ocr_pdf_data)\n",
    "\n",
    "        # Save sentences to JSON\n",
    "        with open(output_json_path, \"w\", encoding=\"utf-8\") as f:\n",
    "            json.dump(sentences, f, indent=4, ensure_ascii=False)\n",
    "        \n",
    "        print(f\"Extracted sentences saved to {output_json_path}\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing '{pdf_url}': {e}\")\n",
    "\n",
    "def process_pdfs_from_urls(pdf_urls, output_json_dir):\n",
    "    \"\"\"Processes multiple PDFs from a list of URLs and extracts text to JSON.\"\"\"\n",
    "    os.makedirs(output_json_dir, exist_ok=True)  # Ensure output directory exists\n",
    "\n",
    "    for pdf_url in pdf_urls:\n",
    "        process_pdf_and_extract_text(pdf_url, output_json_dir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39df71bf-6a5d-44b2-9a0f-8054c9ff4138",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "(4265_assignment1)",
   "language": "python",
   "name": "4265_assignment1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
