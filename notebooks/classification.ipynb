{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "afbcf5a7-9a5a-4e22-8a83-2b118a46ba83",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import requests\n",
    "import time\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch \n",
    "from torch import nn\n",
    "from torch.optim import AdamW  \n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import numpy as np\n",
    "import pandas as pd \n",
    "from transformers import AutoModelForSequenceClassification, AutoModelForCausalLM, AutoTokenizer, pipeline, BertTokenizer, BertModel\n",
    "from transformers import Trainer, TrainingArguments\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tqdm import tqdm\n",
    "torch.set_default_device(\"cpu\")\n",
    "import random\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "50a50819-1d8f-4369-ae0f-f6468631d156",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/chienshiyun/Documents/_DSA3101/proj/dsa3101/notebooks'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae27e421-c198-49eb-acc3-3185eb314c74",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Data Cleaning\n",
    "1. Remove duplicate data \n",
    "2. Handle missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b57d473-2bd1-45ca-b552-06992886bef1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "with open('../dataset_json/Health/Na/Pfizer_2022_ocr.json', 'r', encoding='utf-8') as f:\n",
    "    pfizer_data = json.load(f)  \n",
    "pfizer_df = pd.DataFrame(pfizer_data)\n",
    "pfizer_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a74500b1-9795-4d2c-971c-4fea8f9437e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_path = \"../dataset_json/Tech/AsiaPac/\"\n",
    "\n",
    "json_files = [f for f in os.listdir(folder_path) if f.endswith('.json')]\n",
    "dfs = {}\n",
    "\n",
    "for file in json_files:\n",
    "    file_path = os.path.join(folder_path, file)\n",
    "    with open(file_path, 'r', encoding='utf-8') as f:\n",
    "        data = json.load(f)  # Load JSON file\n",
    "    if isinstance(data, list):  \n",
    "        df = pd.DataFrame(data)\n",
    "    else:\n",
    "        print(f\"Skipping {file}: Unsupported format\")\n",
    "        continue\n",
    "    \n",
    "    dfs[file] = df  \n",
    "dfs['pfizer_2022_ocr.json'] = pfizer_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec03e42d-1ab5-47eb-a2e7-b0093e12ec8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_path = \"../dataset_json/Tech/Na/\"\n",
    "\n",
    "json_files = [f for f in os.listdir(folder_path) if f.endswith('.json')]\n",
    "for file in json_files:\n",
    "    file_path = os.path.join(folder_path, file)\n",
    "    with open(file_path, 'r', encoding='utf-8') as f:\n",
    "        data = json.load(f)  # Load JSON file\n",
    "    if isinstance(data, list):  \n",
    "        df = pd.DataFrame(data)\n",
    "    else:\n",
    "        print(f\"Skipping {file}: Unsupported format\")\n",
    "        continue\n",
    "    \n",
    "    dfs[file] = df  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8c84010-9ca6-4ee5-8d2b-b074f81bbd8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(dfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7029892-50a9-4328-8605-42f178200016",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for df in dfs.values(): \n",
    "    print('df info is')\n",
    "    #print(df.info())\n",
    "    #print(df.describe(include=\"all\") )\n",
    "    #print(df.columns)\n",
    "    #print(df.isnull().sum())\n",
    "    print(df.duplicated().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f639b65c-6153-4f2c-bcb3-a06acdb65a2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_combined = pd.concat([df for df in dfs.values()], ignore_index=True)  \n",
    "missing_rows = df_combined[df_combined.isnull().any(axis=1)]\n",
    "print(len(missing_rows))\n",
    "df_combined.drop_duplicates(inplace=True)\n",
    "df_combined[\"esg_text\"].apply(type).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d94c2f20-ff0b-4517-8e18-992dcef18617",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_combined.drop_duplicates(inplace=True)\n",
    "df_combined[\"esg_text\"].apply(type).value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1610ddfe-5221-4c10-9251-3a174d2aa265",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Data labeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "24e7bf88-95f2-43d2-9f9d-26837204cbaa",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertForSequenceClassification(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-11): 12 x BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSdpaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (classifier): Linear(in_features=768, out_features=26, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "model_name = \"nbroad/ESG-BERT\" #\"nlpaueb/sec-bert-esg\" \n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_name)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "df_combined = pd.read_csv('../combined_pdfs_2602.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "99e7a4d9-7a5a-4700-aed7-846c2d4d95d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                            esg_text      labels\n",
      "0  AOD  MIOLS  YALNNOD  GWNY 766  AGOD  MIOLS  YA...  [No Label]\n",
      "1  This is the 18th consecutive year we have publ...  [No Label]\n",
      "2  Clearly, the past year presented our world wit...  [No Label]\n",
      "3  It is clear that Al will be a major priority a...  [No Label]\n",
      "4  We are committed to accelerating the deploymen...  [No Label]\n"
     ]
    }
   ],
   "source": [
    "candidate_labels = [\"Environment - Energy efficiency\", \"Environment - Waste & Pollutants Generation\", \n",
    "                    \"Environment - Water Usage\", \"Environment - Climate Strategy\", \n",
    "                    \"Environment - Decarbonisation/Carbon emissions\", \"Environment - Strategy\",\n",
    "                    \"Social - Labor Practices\", \"Social - Human Rights\", \"Social - Human Capital Management\", \n",
    "                    \"Social - Occupational Health & Safety\", \"Social - Financial Inclusion\", \"Social - Community investment\",\n",
    "                    \"Social - Customer Relations\",\" Social - Privacy Protection\", 'Social - Gender and Ethnic Diversity',\n",
    "                    \"Governance - Transparency & Reporting\", \"Corporate Governance\", \"Governance - Materiality\", \n",
    "                    \"Governance - Risk & Crisis Management\", \"Governance - Business Ethics\", \n",
    "                    \"Governance - Policy Influence\", \"Governance - Tax Strategy\", \n",
    "                    \"Governance - Shareholder rights\",\n",
    "                    \"Governance - Information Security/ Cybersecurity & System Availability\", \n",
    "                    \"Governance - Sustainable Finance\", \"Governance - Board Diversity\"]\n",
    "\n",
    "# def classify_text(text):\n",
    "#     if pd.isna(text): \n",
    "#         return None\n",
    "\n",
    "#     inputs = tokenizer(text, return_tensors=\"pt\", padding=True, truncation=True, max_length=512).to(device)\n",
    "    \n",
    "#     with torch.no_grad():\n",
    "#         outputs = model(**inputs)\n",
    "\n",
    "#     probabilities = torch.nn.functional.softmax(outputs.logits, dim=1)\n",
    "#     predicted_class = torch.argmax(probabilities, dim=1).item()\n",
    "    \n",
    "#     return candidate_labels[predicted_class]\n",
    "\n",
    "# df_combined[\"labels\"] = df_combined[\"esg_text\"].apply(classify_text)\n",
    "# print(df_combined.head())\n",
    "\n",
    "\n",
    "THRESHOLD = 0.6  \n",
    "def classify_text(text):\n",
    "    if pd.isna(text): \n",
    "        return None\n",
    "\n",
    "    inputs = tokenizer(text, return_tensors=\"pt\", padding=True, truncation=True, max_length=512).to(device)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "\n",
    "    probabilities = torch.nn.functional.softmax(outputs.logits, dim=-1)  # Softmax for classification\n",
    "    probabilities = probabilities.squeeze().cpu().numpy()\n",
    "\n",
    "    if len(probabilities) != len(candidate_labels):\n",
    "        print(f\"Warning: Mismatch! Probabilities: {len(probabilities)}, Labels: {len(candidate_labels)}\")\n",
    "        return [\"Error\"]\n",
    "\n",
    "    assigned_labels = [candidate_labels[i] for i, prob in enumerate(probabilities) if prob > THRESHOLD]\n",
    "    return assigned_labels if assigned_labels else [\"No Label\"]\n",
    "\n",
    "tqdm.pandas()\n",
    "\n",
    "\n",
    "df_combined[\"labels\"] = df_combined[\"esg_text\"].apply(classify_text)\n",
    "print(df_combined.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "532cdb0c-a75e-44f2-b52a-cd58b1b9e9c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>esg_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AOD  MIOLS  YALNNOD  GWNY 766  AGOD  MIOLS  YA...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>This is the 18th consecutive year we have publ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Clearly, the past year presented our world wit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>It is clear that Al will be a major priority a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>We are committed to accelerating the deploymen...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            esg_text\n",
       "0  AOD  MIOLS  YALNNOD  GWNY 766  AGOD  MIOLS  YA...\n",
       "1  This is the 18th consecutive year we have publ...\n",
       "2  Clearly, the past year presented our world wit...\n",
       "3  It is clear that Al will be a major priority a...\n",
       "4  We are committed to accelerating the deploymen..."
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_combined.head(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ef1f4df5-700c-4dbc-9115-f5a64dac8b84",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "labels\n",
       "[No Label]                                                                  4385\n",
       "[Social - Human Capital Management]                                          752\n",
       "[Governance - Transparency & Reporting]                                      564\n",
       "[Social - Customer Relations]                                                505\n",
       "[Governance - Materiality]                                                   463\n",
       "[Environment - Energy efficiency]                                            409\n",
       "[Governance - Board Diversity]                                               384\n",
       "[Governance - Sustainable Finance]                                           378\n",
       "[Social - Financial Inclusion]                                               308\n",
       "[ Social - Privacy Protection]                                               294\n",
       "[Social - Occupational Health & Safety]                                      291\n",
       "[Governance - Business Ethics]                                               275\n",
       "[Environment - Waste & Pollutants Generation]                                261\n",
       "[Social - Community investment]                                              236\n",
       "[Environment - Water Usage]                                                  214\n",
       "[Governance - Policy Influence]                                              171\n",
       "[Governance - Risk & Crisis Management]                                      160\n",
       "[Environment - Climate Strategy]                                             131\n",
       "[Governance - Information Security/ Cybersecurity & System Availability]      96\n",
       "[Governance - Shareholder rights]                                             83\n",
       "[Environment - Decarbonisation/Carbon emissions]                              76\n",
       "[Environment - Strategy]                                                      73\n",
       "[Social - Human Rights]                                                       73\n",
       "[Social - Gender and Ethnic Diversity]                                        58\n",
       "[Governance - Tax Strategy]                                                   54\n",
       "[Corporate Governance]                                                         7\n",
       "[Social - Labor Practices]                                                     1\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_combined['labels'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "07bc10ad-102e-4ce8-993a-f26dba5dc01f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_combined.to_csv('../labeled_pdfs_2602.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82b29ccc-0130-4082-902e-0084d5494f27",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Data transformation\n",
    "Since the data breakdown is \n",
    "Environment:    588\n",
    "Social:         220\n",
    "Governance:     161\n",
    "I had to make the dataset even. I had two appraoches: resampling and data augmentation "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f754a6b5-8f45-46ef-aff7-630962b1e5df",
   "metadata": {},
   "source": [
    "## First method: resampling \n",
    "As the dataset is already very small, I do not want to do undersampling to reduce the dataset size further, so I would prefer to do oversampling. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0d49a78-9a42-42f9-aa7e-a6259b38ad46",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.utils import resample\n",
    "\n",
    "df_env = df_combined[df_combined['labels'] == 'Environment']\n",
    "df_soc = df_combined[df_combined['labels'] == 'Social']\n",
    "df_gov = df_combined[df_combined['labels'] == 'Governance']\n",
    "\n",
    "\n",
    "target_size = max(len(df_soc), len(df_gov))  # Balance to the highest minority class\n",
    "\n",
    "# Oversample Social & Governance\n",
    "df_soc_oversampled = resample(df_soc, replace=True, n_samples=target_size, random_state=42)\n",
    "df_gov_oversampled = resample(df_gov, replace=True, n_samples=target_size, random_state=42)\n",
    "\n",
    "# Undersample Environment\n",
    "df_env_undersampled = resample(df_env, replace=False, n_samples=target_size, random_state=42)\n",
    "\n",
    "# Combine and shuffle balanced dataset\n",
    "df_balanced = pd.concat([df_env_undersampled, df_soc_oversampled, df_gov_oversampled])\n",
    "df_balanced = df_balanced.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "\n",
    "# Check new distribution\n",
    "print(df_balanced['labels'].value_counts()) ## It was 200++ for each component now."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0062f76b-bf24-4e14-ac76-1ee618633cfb",
   "metadata": {},
   "source": [
    "# Model Training with finBERT \n",
    "I decided to use FinBERT as it is built by further training the BERT language model in the finance domain, using a large financial corpus. Even though I am not using the model for financial sentiment classification, I felt that since I am training the model on a classification task on ESG data, which is discussed extensively in the financial sector, it would be good to use a model that was trained in the financial domain. \n",
    "I also found an ESGBERT model on huggingface https://huggingface.co/ESGBERT but I did not have the time to try it. I felt that finBERT was more well known and widely used, thus it would still produce more accurate results.\n",
    "I would like to try it next time, to compare the results between BERT, FinBERT and ESGBert. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b28907c-cb02-4dfd-b547-3579ee518ba0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('labeled_combined_pdfs_2602.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65d1cb2f-8cff-4d23-bcbe-e241c21bd207",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(42)\n",
    "torch.mps.empty_cache()\n",
    "\n",
    "device = (\n",
    "    \"mps\" \n",
    "    if torch.backends.mps.is_available() \n",
    "    else \"cuda\" \n",
    "    if torch.cuda.is_available() \n",
    "    else \"cpu\"\n",
    ")\n",
    "device = torch.device(device)\n",
    "print(f\"Using device: {device}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1878a7d8-9249-427f-9ae7-f21625943bf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_map = {\n",
    "    \"Environment,Energy\" : 11, \n",
    "    \"Environment,Waste & Pollutants\": 12, \n",
    "    \"Environment,Water\": 13, \n",
    "    \"Environment,Climate Strategy\": 14, \n",
    "    \"Environment,Decarbonization\": 15, \n",
    "    \"Environment,Strategy\": 16,\n",
    "    \"Social,Labor Practices\": 21,\n",
    "    \"Social,Human Rights\": 22, \n",
    "    \"Social,Human Capital Management\": 23,\n",
    "    \"Social,Occupational Health & Safety\":24,\n",
    "    \"Social,Financial Inclusion\": 25,           \n",
    "    \"Social,Customer Relations\": 26,\n",
    "    \"Social,Privacy Protection\": 27,\n",
    "    \"Governance,Transparency & Reporting\": 31, \n",
    "    \"Corporate Governance\": 32, \n",
    "    \"Governance,Materiality\": 33, \n",
    "    \"Governance,Risk & Crisis Management\": 34,              \n",
    "    \"Governance,Business Ethics\": 35, \n",
    "    \"Governance,Policy Influence\": 36, \n",
    "    \"Governance,Tax Strategy\": 37, \n",
    "    \"Governance,Information Security/ Cybersecurity & System Availability\": 38, \n",
    "    \"Governance,Sustainable Finance\": 39\n",
    "}\n",
    "\n",
    "df['label'] = df['labels'].map(label_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d7ba093-6a60-4382-ac00-1947db516eb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87d59927-9e23-404e-800b-0bef688ebad8",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_texts, val_texts, train_labels, val_labels = train_test_split(\n",
    "    df['combined_text'].values, \n",
    "    df['label'].values, \n",
    "    test_size=0.2,\n",
    "    random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5560204-a52f-4318-a16a-27066c9ecfbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_NAME = \"yiyanghkust/finbert-tone\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3a7427c-cb18-462e-b1ae-6ffaf5c001b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NewsDataset(Dataset):\n",
    "    def __init__(self, texts, labels, tokenizer, max_length=128):\n",
    "        self.texts = list(map(str, texts))  \n",
    "        self.labels = list(map(str, labels))  \n",
    "        self.labels = [int(label) for label in labels]\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_length = max_length\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        # If we receive a single index\n",
    "        if isinstance(idx, int):\n",
    "            text = str(self.texts[idx])\n",
    "            label = int(self.labels[idx])  \n",
    "    \n",
    "            encoding = self.tokenizer.encode_plus(\n",
    "                text,\n",
    "                add_special_tokens=True,\n",
    "                max_length=self.max_length,\n",
    "                return_token_type_ids=False,\n",
    "                padding='max_length',\n",
    "                truncation=True,\n",
    "                return_attention_mask=True,\n",
    "                return_tensors='pt'\n",
    "            )\n",
    "    \n",
    "            return {\n",
    "                'input_ids': encoding['input_ids'].squeeze(0),  # Remove extra dimension\n",
    "                'attention_mask': encoding['attention_mask'].squeeze(0),\n",
    "                'labels': torch.tensor(label, dtype=torch.long)\n",
    "            }\n",
    "        \n",
    "        # To receive a list of indices (in case of batching)\n",
    "        elif isinstance(idx, list):\n",
    "            batch = [self.__getitem__(i) for i in idx]\n",
    "            \n",
    "            # Return batch as dictionary\n",
    "            return {\n",
    "                'input_ids': torch.stack([item['input_ids'] for item in batch]),\n",
    "                'attention_mask': torch.stack([item['attention_mask'] for item in batch]),\n",
    "                'labels': torch.stack([item['labels'] for item in batch])\n",
    "            }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec69006c-8fb5-4254-a765-0be059edf4f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create datasets\n",
    "train_dataset = NewsDataset(train_texts, train_labels, tokenizer)\n",
    "val_dataset = NewsDataset(val_texts, val_labels, tokenizer)\n",
    "\n",
    "# Create data loaders\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True, collate_fn=None)\n",
    "val_loader = DataLoader(val_dataset, batch_size=32, collate_fn=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eec36926-1eb7-47d5-993b-5780c6310e58",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ESGClassifier(nn.Module):\n",
    "    \"\"\"\n",
    "    Our sentiment classifier model.\n",
    "    It uses BERT as the base model and adds a classification head on top.\n",
    "    \"\"\"\n",
    "    def __init__(self, n_classes=3):\n",
    "        super(ESGClassifier, self).__init__()\n",
    "        self.bert = BertModel.from_pretrained(MODEL_NAME) \n",
    "        self.dropout = nn.Dropout(p=0.3)\n",
    "        self.classifier = nn.Linear(self.bert.config.hidden_size, n_classes)\n",
    "        \n",
    "    def forward(self, input_ids, attention_mask):\n",
    "        outputs = self.bert(\n",
    "            input_ids=input_ids,\n",
    "            attention_mask=attention_mask\n",
    "        )\n",
    "        pooled_output = outputs.pooler_output\n",
    "        output = self.dropout(pooled_output)\n",
    "        return self.classifier(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34c4cd54-deb5-4fac-856a-9d904dd1720f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize model\n",
    "model = ESGClassifier()\n",
    "model = model.to(device)\n",
    "\n",
    "# Initialize optimizer\n",
    "optimizer = AdamW([\n",
    "    {'params': model.bert.parameters(), 'lr': 2e-5}, ## Changed\n",
    "    {'params': model.classifier.parameters(), 'lr': 1e-3}\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f11baa54-b203-49f8-a85b-a071150c8c0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training function\n",
    "def train_epoch(model, data_loader, optimizer, device):\n",
    "    \"\"\"\n",
    "    Trains the model for one epoch and returns the average loss.\n",
    "    \"\"\"\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    \n",
    "    for batch in tqdm(data_loader, desc=\"Training\"):\n",
    "        input_ids = batch['input_ids'].to(device)\n",
    "        attention_mask = batch['attention_mask'].to(device)\n",
    "        labels = batch['labels'].to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        \n",
    "        loss_fn = nn.CrossEntropyLoss()\n",
    "        loss = loss_fn(outputs, labels)\n",
    "        \n",
    "        loss.backward()\n",
    "        \n",
    "        optimizer.step()\n",
    "        \n",
    "        total_loss += loss.item()\n",
    "    \n",
    "    return total_loss / len(data_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0be2e40-955d-4303-88eb-5f7c4e432124",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, data_loader, device):\n",
    "    \"\"\"\n",
    "    Evaluates the model on the provided data loader.\n",
    "    Returns accuracy and average loss.\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    correct_predictions = 0\n",
    "    total_predictions = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(data_loader, desc=\"Evaluating\"):\n",
    "            input_ids = batch['input_ids'].to(device)\n",
    "            attention_mask = batch['attention_mask'].to(device)\n",
    "            labels = batch['labels'].to(device)\n",
    "            \n",
    "            outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "            \n",
    "            loss_fn = nn.CrossEntropyLoss()\n",
    "            loss = loss_fn(outputs, labels)\n",
    "            \n",
    "            _, predictions = torch.max(outputs, dim=1)\n",
    "            \n",
    "            total_loss += loss.item()\n",
    "            correct_predictions += torch.sum(predictions == labels)\n",
    "            total_predictions += labels.shape[0]\n",
    "    \n",
    "    # Use float32 instead of double/float64\n",
    "    accuracy = (correct_predictions.float() / total_predictions) * 100  \n",
    "    average_loss = total_loss / len(data_loader)\n",
    "    \n",
    "    return accuracy, average_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67bf8f33-1d77-4a96-82a5-3287330a4869",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Main training loop\n",
    "def train_model(model, train_loader, val_loader, optimizer, device, epochs=3):\n",
    "    \"\"\"\n",
    "    Main training loop that handles the entire training process.\n",
    "    \"\"\"\n",
    "    best_accuracy = 0\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        print(f'\\nEpoch {epoch + 1}/{epochs}')\n",
    "        \n",
    "        # Train one epoch\n",
    "        train_loss = train_epoch(model, train_loader, optimizer, device)\n",
    "        \n",
    "        # Evaluate\n",
    "        val_accuracy, val_loss = evaluate(model, val_loader, device)\n",
    "        \n",
    "        # Print metrics\n",
    "        print(f'Training Loss: {train_loss:.4f}')\n",
    "        print(f'Validation Loss: {val_loss:.4f}')\n",
    "        print(f'Validation Accuracy: {val_accuracy:.4f}')\n",
    "        \n",
    "        # Save best model\n",
    "        if val_accuracy > best_accuracy:\n",
    "            best_accuracy = val_accuracy\n",
    "            torch.save(model.state_dict(), 'best_model.pt')\n",
    "            print('Best model saved!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e4a4be5-5efe-4e17-a3a7-b867ad460d2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# Train the model\n",
    "train_model(model, train_loader, val_loader, optimizer, device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c82ae8e0-e711-4851-94b9-6fb128f48b4a",
   "metadata": {},
   "source": [
    "# Evaluation \n",
    "Check class distribution and use F1-score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db1740a1-4644-4dff-b49a-313b61dcd0a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
    "\n",
    "def evaluate(model, data_loader, device):\n",
    "    \"\"\"\n",
    "    Evaluates the model and returns accuracy, precision, recall, and F1-score.\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    all_labels = []\n",
    "    all_preds = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(data_loader, desc=\"Evaluating\"):\n",
    "            input_ids = batch['input_ids'].to(device)\n",
    "            attention_mask = batch['attention_mask'].to(device)\n",
    "            labels = batch['labels'].to(device)\n",
    "\n",
    "            outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "            _, predictions = torch.max(outputs, dim=1)  # Get predicted class\n",
    "            \n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "            all_preds.extend(predictions.cpu().numpy())\n",
    "\n",
    "    # Compute metrics\n",
    "    accuracy = accuracy_score(all_labels, all_preds)\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(all_labels, all_preds, average='weighted')\n",
    "\n",
    "    print(f'Accuracy: {accuracy:.4f}')\n",
    "    print(f'Precision: {precision:.4f}')\n",
    "    print(f'Recall: {recall:.4f}')\n",
    "    print(f'F1-Score: {f1:.4f}')\n",
    "\n",
    "    return accuracy, precision, recall, f1\n",
    "evaluate(model, val_loader, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "171e29a8-af91-4248-b28c-d928af233d67",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "import numpy as np\n",
    "\n",
    "def evaluate_auc(model, data_loader, device, num_classes=3):\n",
    "    model.eval()\n",
    "    all_labels = []\n",
    "    all_probs = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(data_loader, desc=\"Evaluating\"):\n",
    "            input_ids = batch['input_ids'].to(device)\n",
    "            attention_mask = batch['attention_mask'].to(device)\n",
    "            labels = batch['labels'].to(device)\n",
    "\n",
    "            outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "            probs = torch.nn.functional.softmax(outputs, dim=1)  # Convert logits to probabilities\n",
    "            \n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "            all_probs.extend(probs.cpu().numpy())\n",
    "\n",
    "    auc_score = roc_auc_score(np.eye(num_classes)[all_labels], all_probs, multi_class=\"ovr\")\n",
    "    print(f\"AUC-ROC Score: {auc_score:.4f}\")\n",
    "    return auc_score\n",
    "\n",
    "evaluate_auc(model, val_loader, device, num_classes=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee9ecfb6-3158-4b6a-9721-9a25858def33",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "class_names = [\"Environmental\", \"Social\", \"Governance\"]\n",
    "\n",
    "def evaluate(model, data_loader, device):\n",
    "    \"\"\"\n",
    "    Evaluates the model and returns accuracy, precision, recall, F1-score.\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    all_labels = []\n",
    "    all_preds = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(data_loader, desc=\"Evaluating\"):\n",
    "            input_ids = batch['input_ids'].to(device)\n",
    "            attention_mask = batch['attention_mask'].to(device)\n",
    "            labels = batch['labels'].to(device)\n",
    "\n",
    "            outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "            _, predictions = torch.max(outputs, dim=1)  # Get predicted class\n",
    "            \n",
    "            all_labels.extend(labels.cpu().numpy())  # Convert tensor to numpy\n",
    "            all_preds.extend(predictions.cpu().numpy())\n",
    "\n",
    "    return all_labels, all_preds  # Return both true labels & predictions\n",
    "\n",
    "\n",
    "\n",
    "def plot_confusion_matrix(all_labels, all_preds, class_names):\n",
    "    cm = confusion_matrix(all_labels, all_preds)\n",
    "\n",
    "    plt.figure(figsize=(6, 5))\n",
    "    sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=class_names, yticklabels=class_names)\n",
    "    plt.xlabel(\"Predicted Label\")\n",
    "    plt.ylabel(\"True Label\")\n",
    "    plt.title(\"Confusion Matrix\")\n",
    "    plt.show()\n",
    "\n",
    "all_labels, all_preds = evaluate(model, val_loader, device)\n",
    "plot_confusion_matrix(all_labels, all_preds, class_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55af55a3-8d1b-4563-a489-137f650b5cae",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# Insert Classified ESG data into PostGreSQL "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8952abd7-ed35-41b4-8865-5e9d901f167a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CREATE TABLE ESG_Scores (\n",
    "#     id SERIAL PRIMARY KEY,\n",
    "#     company_name TEXT NOT NULL,\n",
    "#     year INT NOT NULL,\n",
    "#     carbon_emissions_reduction NUMERIC, \n",
    "#     renewable_energy_usage NUMERIC, \n",
    "#     waste_management NUMERIC,\n",
    "#     workforce_diversity NUMERIC, \n",
    "#     employee_rights NUMERIC, \n",
    "#     product_safety NUMERIC,\n",
    "#     board_independence NUMERIC, \n",
    "#     transparency NUMERIC, \n",
    "#     executive_pay_equity NUMERIC, \n",
    "#     anti_corruption_policies NUMERIC,\n",
    "#     overall_esg_score NUMERIC,  \n",
    "#     created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP\n",
    "# );"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5eb94536-8cbf-4ec0-b223-fe72ccf83ab7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import psycopg2\n",
    "# from datetime import datetime\n",
    "\n",
    "# # PostgreSQL connection\n",
    "# conn = psycopg2.connect(\n",
    "#     dbname=\"your_database\",\n",
    "#     user=\"your_user\",\n",
    "#     password=\"your_password\",\n",
    "#     host=\"localhost\",\n",
    "#     port=\"5432\"\n",
    "# )\n",
    "# cursor = conn.cursor()\n",
    "\n",
    "# # Example extracted ESG data\n",
    "# esg_data = {\n",
    "#     \"company_name\": \"Pfizer\",\n",
    "#     \"year\": 2023,\n",
    "#     \"carbon_emissions_reduction\": 7.5,\n",
    "#     \"renewable_energy_usage\": 8.0,\n",
    "#     \"waste_management\": 7.0,\n",
    "#     \"workforce_diversity\": 6.5,\n",
    "#     \"employee_rights\": 8.0,\n",
    "#     \"product_safety\": 7.5,\n",
    "#     \"board_independence\": 8.5,\n",
    "#     \"transparency\": 8.0,\n",
    "#     \"executive_pay_equity\": 6.0,\n",
    "#     \"anti_corruption_policies\": 7.5,\n",
    "#     \"overall_esg_score\": 7.43\n",
    "# }\n",
    "\n",
    "# # SQL INSERT query\n",
    "# query = \"\"\"\n",
    "# INSERT INTO ESG_Scores (company_name, year, carbon_emissions_reduction, renewable_energy_usage,\n",
    "#                         waste_management, workforce_diversity, employee_rights, product_safety,\n",
    "#                         board_independence, transparency, executive_pay_equity, anti_corruption_policies, \n",
    "#                         overall_esg_score, created_at) \n",
    "# VALUES (%s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s)\n",
    "# \"\"\"\n",
    "\n",
    "# # Execute query\n",
    "# cursor.execute(query, (\n",
    "#     esg_data[\"company_name\"], esg_data[\"year\"], esg_data[\"carbon_emissions_reduction\"],\n",
    "#     esg_data[\"renewable_energy_usage\"], esg_data[\"waste_management\"], esg_data[\"workforce_diversity\"],\n",
    "#     esg_data[\"employee_rights\"], esg_data[\"product_safety\"], esg_data[\"board_independence\"],\n",
    "#     esg_data[\"transparency\"], esg_data[\"executive_pay_equity\"], esg_data[\"anti_corruption_policies\"],\n",
    "#     esg_data[\"overall_esg_score\"], datetime.now()\n",
    "# ))\n",
    "\n",
    "# # Commit and close\n",
    "# conn.commit()\n",
    "# cursor.close()\n",
    "# conn.close()\n",
    "\n",
    "# print(\"ESG data inserted successfully!\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "(4265_assignment1)",
   "language": "python",
   "name": "4265_assignment1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
