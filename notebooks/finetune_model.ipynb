{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "afbcf5a7-9a5a-4e22-8a83-2b118a46ba83",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "#os.chdir('/Users/chienshiyun/Documents/_DSA3101/proj/dsa3101/')\n",
    "import requests\n",
    "import time\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch \n",
    "from torch import nn\n",
    "from torch.optim import AdamW  \n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import numpy as np\n",
    "import pandas as pd \n",
    "from transformers import AutoModelForSequenceClassification, AutoModelForCausalLM, AutoTokenizer, pipeline, BertTokenizer, BertModel\n",
    "from transformers import Trainer, TrainingArguments\n",
    "import spacy\n",
    "from spacy import displacy\n",
    "import ast\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tqdm import tqdm\n",
    "import random\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdcda9b6-1c6c-445a-9bd1-2b0cc3ad0074",
   "metadata": {},
   "source": [
    "# Data cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07bc10ad-102e-4ce8-993a-f26dba5dc01f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('human_labeled_pdfs_0903.csv')\n",
    "filtered_df = df[['esg_text', 'human_labels']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4a5b0bb-6372-4676-a651-e207a9accf5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ensure_list_format(label):\n",
    "    label = str(label).strip()  \n",
    "    if not (label.startswith(\"[\") and label.endswith(\"]\")):\n",
    "        return f\"[{label}]\"  \n",
    "    return label  \n",
    "\n",
    "filtered_df[\"human_labels\"] = filtered_df[\"human_labels\"].apply(ensure_list_format)\n",
    "filtered_df[\"human_labels\"] = filtered_df[\"human_labels\"].str.replace(\"'\", '\"')\n",
    "print(filtered_df.head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eedae483-a7f0-4eb7-94fd-6bf772622377",
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_df = filtered_df[filtered_df['human_labels'].apply(lambda x: len(x) > 0)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48453cc4-55c0-49b9-b700-45a43e18dcec",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_map = {\n",
    "    \"No Label\": 0,\n",
    "    \"Environment - Energy efficiency\" : 1, \n",
    "    \"Environment - Waste & Pollutants Generation\": 2, \n",
    "    \"Environment - Water Usage\": 3, \n",
    "    \"Environment - Climate Strategy\": 4, \n",
    "    \"Environment - Decarbonisation/Carbon emissions\": 5, \n",
    "    \"Environment - Strategy\": 6,\n",
    "    \"Social - Gender and Ethnic Diversity\": 7,\n",
    "    \"Social - Labor Practices\": 8,\n",
    "    \"Social - Human Rights\": 9, \n",
    "    \"Social - Human Capital Management\": 10,\n",
    "    \"Social - Occupational Health & Safety\":11,\n",
    "    \"Social - Financial Inclusion\": 12,           \n",
    "    \"Social - Customer Relations\": 13,\n",
    "    \"Social - Privacy Protection\": 14,\n",
    "    \"Social - Community investment\": 15,\n",
    "    \"Social - Human Capital Management\": 16,\n",
    "    \"Governance - Board Diversity\":17,\n",
    "    \"Governance - Transparency & Reporting\": 18, \n",
    "    \"Corporate Governance\": 19, \n",
    "    \"Governance - Materiality\": 20, \n",
    "    \"Governance - Risk & Crisis Management\": 21,              \n",
    "    \"Governance - Business Ethics\": 22, \n",
    "    \"Governance - Policy Influence\": 23, \n",
    "    \"Governance - Tax Strategy\": 24, \n",
    "    \"Governance - Information Security/ Cybersecurity & System Availability\": 25, \n",
    "    \"Governance - Sustainable Finance\": 26,\n",
    "    \"Governance - Shareholder rights\": 27\n",
    "}\n",
    "\n",
    "def map_labels(label_list):\n",
    "    if isinstance(label_list, list):  \n",
    "        return [label_map[label] for label in label_list if label in label_map]\n",
    "    return []  \n",
    "\n",
    "filtered_df['label'] = filtered_df['human_labels'].apply(map_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92a67747-bea3-427e-9036-6f14b524650b",
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_df['label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "950623cb-8458-4be2-80bf-34a2cc650892",
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_df.to_csv('human_finetune_trgset.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f754a6b5-8f45-46ef-aff7-630962b1e5df",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Resampling \n",
    "As the dataset is quite small, I do not want to do undersampling to reduce the dataset size further, so I would prefer to do oversampling. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0d49a78-9a42-42f9-aa7e-a6259b38ad46",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# from sklearn.utils import resample\n",
    "\n",
    "# df_env = df_combined[df_combined['labels'] == 'Environment']\n",
    "# df_soc = df_combined[df_combined['labels'] == 'Social']\n",
    "# df_gov = df_combined[df_combined['labels'] == 'Governance']\n",
    "\n",
    "\n",
    "# target_size = max(len(df_soc), len(df_gov))  # Balance to the highest minority class\n",
    "\n",
    "# # Oversample Social & Governance\n",
    "# df_soc_oversampled = resample(df_soc, replace=True, n_samples=target_size, random_state=42)\n",
    "# df_gov_oversampled = resample(df_gov, replace=True, n_samples=target_size, random_state=42)\n",
    "\n",
    "# # Undersample Environment\n",
    "# df_env_undersampled = resample(df_env, replace=False, n_samples=target_size, random_state=42)\n",
    "\n",
    "# # Combine and shuffle balanced dataset\n",
    "# df_balanced = pd.concat([df_env_undersampled, df_soc_oversampled, df_gov_oversampled])\n",
    "# df_balanced = df_balanced.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "\n",
    "# # Check new distribution\n",
    "# print(df_balanced['labels'].value_counts()) ## It was 200++ for each component now."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33e7dedf-9ca5-4e98-90c3-de92b3d2491a",
   "metadata": {},
   "source": [
    "# Model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3b41990c-a3b4-4d55-8d9e-f188cc3ca222",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('human_finetune_trgset.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9cdbb64c-6254-4f20-8ea2-ceceb331f0ae",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "label\n",
       "[0]     967\n",
       "[18]    334\n",
       "[16]    195\n",
       "[22]    132\n",
       "[26]    129\n",
       "[13]    110\n",
       "[6]     106\n",
       "[2]     105\n",
       "[20]    103\n",
       "[21]     98\n",
       "[15]     89\n",
       "[14]     73\n",
       "[5]      68\n",
       "[1]      65\n",
       "[11]     56\n",
       "[25]     46\n",
       "[19]     46\n",
       "[8]      44\n",
       "[12]     39\n",
       "[9]      38\n",
       "[4]      34\n",
       "[7]      32\n",
       "[17]     28\n",
       "[23]     26\n",
       "[3]      26\n",
       "[27]      3\n",
       "[24]      2\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "87d59927-9e23-404e-800b-0bef688ebad8",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_texts, val_texts, train_labels, val_labels = train_test_split(\n",
    "    df['esg_text'].values, \n",
    "    df['label'].apply(lambda x: ast.literal_eval(x) if isinstance(x, str) else x), \n",
    "    test_size=0.2,\n",
    "    random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f5560204-a52f-4318-a16a-27066c9ecfbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_NAME = \"nbroad/ESG-BERT\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b3a7427c-cb18-462e-b1ae-6ffaf5c001b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NewsDataset(Dataset):\n",
    "    def __init__(self, texts, labels, tokenizer, max_length=128):\n",
    "        self.texts = list(map(str, texts))  \n",
    "        self.labels = [int(label[0]) if isinstance(label, list) else int(label) for label in labels]\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_length = max_length\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        # If we receive a single index\n",
    "        if isinstance(idx, int):\n",
    "            text = str(self.texts[idx])\n",
    "            label = int(self.labels[idx])  \n",
    "    \n",
    "            encoding = self.tokenizer.encode_plus(\n",
    "                text,\n",
    "                add_special_tokens=True,\n",
    "                max_length=self.max_length,\n",
    "                return_token_type_ids=False,\n",
    "                padding='max_length',\n",
    "                truncation=True,\n",
    "                return_attention_mask=True,\n",
    "                return_tensors='pt'\n",
    "            )\n",
    "    \n",
    "            return {\n",
    "                'input_ids': encoding['input_ids'].squeeze(0),  # Remove extra dimension\n",
    "                'attention_mask': encoding['attention_mask'].squeeze(0),\n",
    "                'labels': torch.tensor(label, dtype=torch.long)\n",
    "            }\n",
    "        \n",
    "        # To receive a list of indices (in case of batching)\n",
    "        elif isinstance(idx, list):\n",
    "            batch = [self.__getitem__(i) for i in idx]\n",
    "            \n",
    "            # Return batch as dictionary\n",
    "            return {\n",
    "                'input_ids': torch.stack([item['input_ids'] for item in batch]),\n",
    "                'attention_mask': torch.stack([item['attention_mask'] for item in batch]),\n",
    "                'labels': torch.stack([item['labels'] for item in batch])\n",
    "            }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ec69006c-8fb5-4254-a765-0be059edf4f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = NewsDataset(train_texts, train_labels, tokenizer)\n",
    "val_dataset = NewsDataset(val_texts, val_labels, tokenizer)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True, collate_fn=None)\n",
    "val_loader = DataLoader(val_dataset, batch_size=32, collate_fn=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "eec36926-1eb7-47d5-993b-5780c6310e58",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ESGClassifier(nn.Module):\n",
    "    def __init__(self, n_classes=28):\n",
    "        super(ESGClassifier, self).__init__()\n",
    "        self.bert = BertModel.from_pretrained(MODEL_NAME) \n",
    "        self.dropout = nn.Dropout(p=0.3)\n",
    "        self.classifier = nn.Linear(self.bert.config.hidden_size, n_classes)\n",
    "        \n",
    "    def forward(self, input_ids, attention_mask):\n",
    "        outputs = self.bert(\n",
    "            input_ids=input_ids,\n",
    "            attention_mask=attention_mask\n",
    "        )\n",
    "        pooled_output = outputs.pooler_output\n",
    "        output = self.dropout(pooled_output)\n",
    "        return self.classifier(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "34c4cd54-deb5-4fac-856a-9d904dd1720f",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cpu')\n",
    "model = ESGClassifier()\n",
    "model = model.to(device)\n",
    "\n",
    "# Initialize optimizer\n",
    "optimizer = AdamW([\n",
    "    {'params': model.bert.parameters(), 'lr': 2e-5}, ## Changed\n",
    "    {'params': model.classifier.parameters(), 'lr': 1e-3}\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f11baa54-b203-49f8-a85b-a071150c8c0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training function\n",
    "def train_epoch(model, data_loader, optimizer, device):\n",
    "    \"\"\"\n",
    "    Trains the model for one epoch and returns the average loss.\n",
    "    \"\"\"\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    \n",
    "    for batch in tqdm(data_loader, desc=\"Training\"):\n",
    "        input_ids = batch['input_ids'].to(device)\n",
    "        attention_mask = batch['attention_mask'].to(device)\n",
    "        labels = batch['labels'].to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        \n",
    "        loss_fn = nn.CrossEntropyLoss()\n",
    "        loss = loss_fn(outputs, labels)\n",
    "        \n",
    "        loss.backward()\n",
    "        \n",
    "        optimizer.step()\n",
    "        \n",
    "        total_loss += loss.item()\n",
    "    \n",
    "    return total_loss / len(data_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f0be2e40-955d-4303-88eb-5f7c4e432124",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, data_loader, device):\n",
    "    \"\"\"\n",
    "    Evaluates the model on the provided data loader.\n",
    "    Returns accuracy and average loss.\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    correct_predictions = 0\n",
    "    total_predictions = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(data_loader, desc=\"Evaluating\"):\n",
    "            input_ids = batch['input_ids'].to(device)\n",
    "            attention_mask = batch['attention_mask'].to(device)\n",
    "            labels = batch['labels'].to(device)\n",
    "            \n",
    "            outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "            \n",
    "            loss_fn = nn.CrossEntropyLoss()\n",
    "            loss = loss_fn(outputs, labels)\n",
    "            \n",
    "            _, predictions = torch.max(outputs, dim=1)\n",
    "            \n",
    "            total_loss += loss.item()\n",
    "            correct_predictions += torch.sum(predictions == labels)\n",
    "            total_predictions += labels.shape[0]\n",
    "    \n",
    "    # Use float32 instead of double/float64\n",
    "    accuracy = (correct_predictions.float() / total_predictions) * 100  \n",
    "    average_loss = total_loss / len(data_loader)\n",
    "    \n",
    "    return accuracy, average_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "67bf8f33-1d77-4a96-82a5-3287330a4869",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Main training loop\n",
    "def train_model(model, train_loader, val_loader, optimizer, device, epochs=3):\n",
    "    \"\"\"\n",
    "    Main training loop that handles the entire training process.\n",
    "    \"\"\"\n",
    "    best_accuracy = 0\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        print(f'\\nEpoch {epoch + 1}/{epochs}')\n",
    "        \n",
    "        # Train one epoch\n",
    "        train_loss = train_epoch(model, train_loader, optimizer, device)\n",
    "        \n",
    "        # Evaluate\n",
    "        val_accuracy, val_loss = evaluate(model, val_loader, device)\n",
    "        \n",
    "        # Print metrics\n",
    "        print(f'Training Loss: {train_loss:.4f}')\n",
    "        print(f'Validation Loss: {val_loss:.4f}')\n",
    "        print(f'Validation Accuracy: {val_accuracy:.4f}')\n",
    "        \n",
    "        # Save best model\n",
    "        if val_accuracy > best_accuracy:\n",
    "            best_accuracy = val_accuracy\n",
    "            # torch.save(model.state_dict(), 'esgbert_model_weights.pt') #saves model's learned parameters (weights)\n",
    "            torch.save(model, \"esgbert_model_full.pth\") #saves full model architecture\n",
    "            print('ESG-BERT model saved!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4e4a4be5-5efe-4e17-a3a7-b867ad460d2b",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1/3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   7%|██▎                               | 5/75 [01:47<25:11, 21.60s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "File \u001b[0;32m<timed eval>:2\u001b[0m\n",
      "Cell \u001b[0;32mIn[14], line 12\u001b[0m, in \u001b[0;36mtrain_model\u001b[0;34m(model, train_loader, val_loader, optimizer, device, epochs)\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mEpoch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;250m \u001b[39m\u001b[38;5;241m+\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepochs\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     11\u001b[0m \u001b[38;5;66;03m# Train one epoch\u001b[39;00m\n\u001b[0;32m---> 12\u001b[0m train_loss \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_epoch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;66;03m# Evaluate\u001b[39;00m\n\u001b[1;32m     15\u001b[0m val_accuracy, val_loss \u001b[38;5;241m=\u001b[39m evaluate(model, val_loader, device)\n",
      "Cell \u001b[0;32mIn[12], line 21\u001b[0m, in \u001b[0;36mtrain_epoch\u001b[0;34m(model, data_loader, optimizer, device)\u001b[0m\n\u001b[1;32m     18\u001b[0m loss_fn \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mCrossEntropyLoss()\n\u001b[1;32m     19\u001b[0m loss \u001b[38;5;241m=\u001b[39m loss_fn(outputs, labels)\n\u001b[0;32m---> 21\u001b[0m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     23\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[1;32m     25\u001b[0m total_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m loss\u001b[38;5;241m.\u001b[39mitem()\n",
      "File \u001b[0;32m~/miniconda3/envs/4265_assignment1/lib/python3.9/site-packages/torch/_tensor.py:522\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    512\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    513\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    514\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    515\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    520\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[1;32m    521\u001b[0m     )\n\u001b[0;32m--> 522\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    523\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[1;32m    524\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/4265_assignment1/lib/python3.9/site-packages/torch/autograd/__init__.py:266\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    261\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    263\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[1;32m    264\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    265\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 266\u001b[0m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    267\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    268\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    269\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    270\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    271\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    272\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    273\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    274\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# Train the model\n",
    "train_model(model, train_loader, val_loader, optimizer, device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c82ae8e0-e711-4851-94b9-6fb128f48b4a",
   "metadata": {},
   "source": [
    "# Evaluation \n",
    "Check class distribution and use F1-score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db1740a1-4644-4dff-b49a-313b61dcd0a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
    "\n",
    "def evaluate(model, data_loader, device):\n",
    "    \"\"\"\n",
    "    Evaluates the model and returns accuracy, precision, recall, and F1-score.\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    all_labels = []\n",
    "    all_preds = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(data_loader, desc=\"Evaluating\"):\n",
    "            input_ids = batch['input_ids'].to(device)\n",
    "            attention_mask = batch['attention_mask'].to(device)\n",
    "            labels = batch['labels'].to(device)\n",
    "\n",
    "            outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "            _, predictions = torch.max(outputs, dim=1)  # Get predicted class\n",
    "            \n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "            all_preds.extend(predictions.cpu().numpy())\n",
    "\n",
    "    # Compute metrics\n",
    "    accuracy = accuracy_score(all_labels, all_preds)\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(all_labels, all_preds, average='weighted')\n",
    "\n",
    "    print(f'Accuracy: {accuracy:.4f}')\n",
    "    print(f'Precision: {precision:.4f}')\n",
    "    print(f'Recall: {recall:.4f}')\n",
    "    print(f'F1-Score: {f1:.4f}')\n",
    "\n",
    "    return accuracy, precision, recall, f1\n",
    "evaluate(model, val_loader, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "171e29a8-af91-4248-b28c-d928af233d67",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "import numpy as np\n",
    "\n",
    "def evaluate_auc(model, data_loader, device, num_classes=3):\n",
    "    model.eval()\n",
    "    all_labels = []\n",
    "    all_probs = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(data_loader, desc=\"Evaluating\"):\n",
    "            input_ids = batch['input_ids'].to(device)\n",
    "            attention_mask = batch['attention_mask'].to(device)\n",
    "            labels = batch['labels'].to(device)\n",
    "\n",
    "            outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "            probs = torch.nn.functional.softmax(outputs, dim=1)  # Convert logits to probabilities\n",
    "            \n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "            all_probs.extend(probs.cpu().numpy())\n",
    "\n",
    "    auc_score = roc_auc_score(np.eye(num_classes)[all_labels], all_probs, multi_class=\"ovr\")\n",
    "    print(f\"AUC-ROC Score: {auc_score:.4f}\")\n",
    "    return auc_score\n",
    "\n",
    "evaluate_auc(model, val_loader, device, num_classes=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee9ecfb6-3158-4b6a-9721-9a25858def33",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "class_names = [\"Environmental\", \"Social\", \"Governance\"]\n",
    "\n",
    "def evaluate(model, data_loader, device):\n",
    "    \"\"\"\n",
    "    Evaluates the model and returns accuracy, precision, recall, F1-score.\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    all_labels = []\n",
    "    all_preds = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(data_loader, desc=\"Evaluating\"):\n",
    "            input_ids = batch['input_ids'].to(device)\n",
    "            attention_mask = batch['attention_mask'].to(device)\n",
    "            labels = batch['labels'].to(device)\n",
    "\n",
    "            outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "            _, predictions = torch.max(outputs, dim=1)  # Get predicted class\n",
    "            \n",
    "            all_labels.extend(labels.cpu().numpy())  # Convert tensor to numpy\n",
    "            all_preds.extend(predictions.cpu().numpy())\n",
    "\n",
    "    return all_labels, all_preds  # Return both true labels & predictions\n",
    "\n",
    "\n",
    "\n",
    "def plot_confusion_matrix(all_labels, all_preds, class_names):\n",
    "    cm = confusion_matrix(all_labels, all_preds)\n",
    "\n",
    "    plt.figure(figsize=(6, 5))\n",
    "    sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=class_names, yticklabels=class_names)\n",
    "    plt.xlabel(\"Predicted Label\")\n",
    "    plt.ylabel(\"True Label\")\n",
    "    plt.title(\"Confusion Matrix\")\n",
    "    plt.show()\n",
    "\n",
    "all_labels, all_preds = evaluate(model, val_loader, device)\n",
    "plot_confusion_matrix(all_labels, all_preds, class_names)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "(4265_assignment1)",
   "language": "python",
   "name": "4265_assignment1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
