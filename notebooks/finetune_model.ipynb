{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afbcf5a7-9a5a-4e22-8a83-2b118a46ba83",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import requests\n",
    "import time\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch \n",
    "from torch import nn\n",
    "from torch.optim import AdamW  \n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import numpy as np\n",
    "import pandas as pd \n",
    "from transformers import AutoModelForSequenceClassification, AutoModelForCausalLM, AutoTokenizer, pipeline, BertTokenizer, BertModel\n",
    "from transformers import Trainer, TrainingArguments\n",
    "import spacy\n",
    "from spacy import displacy\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tqdm import tqdm\n",
    "torch.set_default_device(\"cpu\")\n",
    "import random\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b57d473-2bd1-45ca-b552-06992886bef1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "with open('../dataset_json/Health/Na/Pfizer_2022_ocr.json', 'r', encoding='utf-8') as f:\n",
    "    pfizer_data = json.load(f)  \n",
    "pfizer_df = pd.DataFrame(pfizer_data)\n",
    "pfizer_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a74500b1-9795-4d2c-971c-4fea8f9437e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_path = \"../dataset_json/Tech/AsiaPac/\"\n",
    "\n",
    "json_files = [f for f in os.listdir(folder_path) if f.endswith('.json')]\n",
    "dfs = {}\n",
    "\n",
    "for file in json_files:\n",
    "    file_path = os.path.join(folder_path, file)\n",
    "    with open(file_path, 'r', encoding='utf-8') as f:\n",
    "        data = json.load(f)  # Load JSON file\n",
    "    if isinstance(data, list):  \n",
    "        df = pd.DataFrame(data)\n",
    "    else:\n",
    "        print(f\"Skipping {file}: Unsupported format\")\n",
    "        continue\n",
    "    \n",
    "    dfs[file] = df  \n",
    "dfs['pfizer_2022_ocr.json'] = pfizer_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec03e42d-1ab5-47eb-a2e7-b0093e12ec8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_path = \"../dataset_json/Tech/Na/\"\n",
    "\n",
    "json_files = [f for f in os.listdir(folder_path) if f.endswith('.json')]\n",
    "for file in json_files:\n",
    "    file_path = os.path.join(folder_path, file)\n",
    "    with open(file_path, 'r', encoding='utf-8') as f:\n",
    "        data = json.load(f)  # Load JSON file\n",
    "    if isinstance(data, list):  \n",
    "        df = pd.DataFrame(data)\n",
    "    else:\n",
    "        print(f\"Skipping {file}: Unsupported format\")\n",
    "        continue\n",
    "    \n",
    "    dfs[file] = df  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8c84010-9ca6-4ee5-8d2b-b074f81bbd8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(dfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7029892-50a9-4328-8605-42f178200016",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for df in dfs.values(): \n",
    "    print('df info is')\n",
    "    #print(df.info())\n",
    "    #print(df.describe(include=\"all\") )\n",
    "    #print(df.columns)\n",
    "    #print(df.isnull().sum())\n",
    "    print(df.duplicated().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f639b65c-6153-4f2c-bcb3-a06acdb65a2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_combined = pd.concat([df for df in dfs.values()], ignore_index=True)  \n",
    "missing_rows = df_combined[df_combined.isnull().any(axis=1)]\n",
    "print(len(missing_rows))\n",
    "df_combined.drop_duplicates(inplace=True)\n",
    "df_combined[\"esg_text\"].apply(type).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d94c2f20-ff0b-4517-8e18-992dcef18617",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_combined.drop_duplicates(inplace=True)\n",
    "df_combined[\"esg_text\"].apply(type).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24e7bf88-95f2-43d2-9f9d-26837204cbaa",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "model_name = \"nbroad/ESG-BERT\" #\"nlpaueb/sec-bert-esg\" \n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_name)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99e7a4d9-7a5a-4700-aed7-846c2d4d95d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "candidate_labels = [\"Environment - Energy efficiency\", \"Environment - Waste & Pollutants Generation\", \n",
    "                    \"Environment - Water Usage\", \"Environment - Climate Strategy\", \n",
    "                    \"Environment - Decarbonisation/Carbon emissions\", \"Environment - Strategy\",\n",
    "                    \"Social - Labor Practices\", \"Social - Human Rights\", \"Social - Human Capital Management\", \n",
    "                    \"Social - Occupational Health & Safety\", \"Social - Financial Inclusion\", \"Social - Community investment\",\n",
    "                    \"Social - Customer Relations\",\"Social - Privacy Protection\", 'Social - Gender and Ethnic Diversity',\n",
    "                    \"Governance - Transparency & Reporting\", \"Corporate Governance\", \"Governance - Materiality\", \n",
    "                    \"Governance - Risk & Crisis Management\", \"Governance - Business Ethics\", \n",
    "                    \"Governance - Policy Influence\", \"Governance - Tax Strategy\", \n",
    "                    \"Governance - Shareholder rights\",\n",
    "                    \"Governance - Information Security/ Cybersecurity & System Availability\", \n",
    "                    \"Governance - Sustainable Finance\", \"Governance - Board Diversity\"]\n",
    "\n",
    "THRESHOLD=0.5\n",
    "def classify_text(text):\n",
    "    if pd.isna(text): \n",
    "        return None\n",
    "\n",
    "    inputs = tokenizer(text, return_tensors=\"pt\", padding=True, truncation=True, max_length=512).to(device)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "\n",
    "    probabilities = torch.nn.functional.softmax(outputs.logits, dim=-1)  # Softmax for classification\n",
    "    probabilities = probabilities.squeeze().cpu().numpy()\n",
    "\n",
    "    if len(probabilities) != len(candidate_labels):\n",
    "        print(f\"Warning: Mismatch! Probabilities: {len(probabilities)}, Labels: {len(candidate_labels)}\")\n",
    "        return [\"Error\"]\n",
    "\n",
    "    assigned_labels = [candidate_labels[i] for i, prob in enumerate(probabilities) if prob > THRESHOLD]\n",
    "    return assigned_labels if assigned_labels else [\"No Label\"]\n",
    "\n",
    "tqdm.pandas()\n",
    "\n",
    "\n",
    "df_combined[\"labels\"] = df_combined[\"esg_text\"].apply(classify_text)\n",
    "print(df_combined.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "532cdb0c-a75e-44f2-b52a-cd58b1b9e9c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_combined.head(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef1f4df5-700c-4dbc-9115-f5a64dac8b84",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_combined['labels'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07bc10ad-102e-4ce8-993a-f26dba5dc01f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_combined.to_csv('../labeled_pdfs_2802.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f754a6b5-8f45-46ef-aff7-630962b1e5df",
   "metadata": {
    "tags": []
   },
   "source": [
    "## First method: resampling \n",
    "As the dataset is already very small, I do not want to do undersampling to reduce the dataset size further, so I would prefer to do oversampling. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0d49a78-9a42-42f9-aa7e-a6259b38ad46",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.utils import resample\n",
    "\n",
    "df_env = df_combined[df_combined['labels'] == 'Environment']\n",
    "df_soc = df_combined[df_combined['labels'] == 'Social']\n",
    "df_gov = df_combined[df_combined['labels'] == 'Governance']\n",
    "\n",
    "\n",
    "target_size = max(len(df_soc), len(df_gov))  # Balance to the highest minority class\n",
    "\n",
    "# Oversample Social & Governance\n",
    "df_soc_oversampled = resample(df_soc, replace=True, n_samples=target_size, random_state=42)\n",
    "df_gov_oversampled = resample(df_gov, replace=True, n_samples=target_size, random_state=42)\n",
    "\n",
    "# Undersample Environment\n",
    "df_env_undersampled = resample(df_env, replace=False, n_samples=target_size, random_state=42)\n",
    "\n",
    "# Combine and shuffle balanced dataset\n",
    "df_balanced = pd.concat([df_env_undersampled, df_soc_oversampled, df_gov_oversampled])\n",
    "df_balanced = df_balanced.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "\n",
    "# Check new distribution\n",
    "print(df_balanced['labels'].value_counts()) ## It was 200++ for each component now."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33e7dedf-9ca5-4e98-90c3-de92b3d2491a",
   "metadata": {},
   "source": [
    "## Model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fa188ba-75da-4bba-80fb-58652bed1d38",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../files/label_map_2802.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87d59927-9e23-404e-800b-0bef688ebad8",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_texts, val_texts, train_labels, val_labels = train_test_split(\n",
    "    df['esg_text'].values, \n",
    "    df['label'].values, \n",
    "    test_size=0.2,\n",
    "    random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3199b45b-8cf6-4513-8f21-327066536b6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(train_texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5560204-a52f-4318-a16a-27066c9ecfbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_NAME = \"nbroad/ESG-BERT\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3a7427c-cb18-462e-b1ae-6ffaf5c001b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NewsDataset(Dataset):\n",
    "    def __init__(self, texts, labels, tokenizer, max_length=128):\n",
    "        self.texts = list(map(str, texts))  \n",
    "        self.labels = list(map(str, labels))  \n",
    "        self.labels = [int(label[0]) for label in labels]\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_length = max_length\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        # If we receive a single index\n",
    "        if isinstance(idx, int):\n",
    "            text = str(self.texts[idx])\n",
    "            label = int(self.labels[idx])  \n",
    "    \n",
    "            encoding = self.tokenizer.encode_plus(\n",
    "                text,\n",
    "                add_special_tokens=True,\n",
    "                max_length=self.max_length,\n",
    "                return_token_type_ids=False,\n",
    "                padding='max_length',\n",
    "                truncation=True,\n",
    "                return_attention_mask=True,\n",
    "                return_tensors='pt'\n",
    "            )\n",
    "    \n",
    "            return {\n",
    "                'input_ids': encoding['input_ids'].squeeze(0),  # Remove extra dimension\n",
    "                'attention_mask': encoding['attention_mask'].squeeze(0),\n",
    "                'labels': torch.tensor(label, dtype=torch.long)\n",
    "            }\n",
    "        \n",
    "        # To receive a list of indices (in case of batching)\n",
    "        elif isinstance(idx, list):\n",
    "            batch = [self.__getitem__(i) for i in idx]\n",
    "            \n",
    "            # Return batch as dictionary\n",
    "            return {\n",
    "                'input_ids': torch.stack([item['input_ids'] for item in batch]),\n",
    "                'attention_mask': torch.stack([item['attention_mask'] for item in batch]),\n",
    "                'labels': torch.stack([item['labels'] for item in batch])\n",
    "            }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec69006c-8fb5-4254-a765-0be059edf4f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create datasets\n",
    "train_dataset = NewsDataset(train_texts, train_labels, tokenizer)\n",
    "val_dataset = NewsDataset(val_texts, val_labels, tokenizer)\n",
    "\n",
    "# Create data loaders\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True, collate_fn=None)\n",
    "val_loader = DataLoader(val_dataset, batch_size=32, collate_fn=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eec36926-1eb7-47d5-993b-5780c6310e58",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ESGClassifier(nn.Module):\n",
    "    def __init__(self, n_classes=3):\n",
    "        super(ESGClassifier, self).__init__()\n",
    "        self.bert = BertModel.from_pretrained(MODEL_NAME) \n",
    "        self.dropout = nn.Dropout(p=0.3)\n",
    "        self.classifier = nn.Linear(self.bert.config.hidden_size, n_classes)\n",
    "        \n",
    "    def forward(self, input_ids, attention_mask):\n",
    "        outputs = self.bert(\n",
    "            input_ids=input_ids,\n",
    "            attention_mask=attention_mask\n",
    "        )\n",
    "        pooled_output = outputs.pooler_output\n",
    "        output = self.dropout(pooled_output)\n",
    "        return self.classifier(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34c4cd54-deb5-4fac-856a-9d904dd1720f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize model\n",
    "model = ESGClassifier()\n",
    "model = model.to(device)\n",
    "\n",
    "# Initialize optimizer\n",
    "optimizer = AdamW([\n",
    "    {'params': model.bert.parameters(), 'lr': 2e-5}, ## Changed\n",
    "    {'params': model.classifier.parameters(), 'lr': 1e-3}\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f11baa54-b203-49f8-a85b-a071150c8c0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training function\n",
    "def train_epoch(model, data_loader, optimizer, device):\n",
    "    \"\"\"\n",
    "    Trains the model for one epoch and returns the average loss.\n",
    "    \"\"\"\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    \n",
    "    for batch in tqdm(data_loader, desc=\"Training\"):\n",
    "        input_ids = batch['input_ids'].to(device)\n",
    "        attention_mask = batch['attention_mask'].to(device)\n",
    "        labels = batch['labels'].to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        \n",
    "        loss_fn = nn.CrossEntropyLoss()\n",
    "        loss = loss_fn(outputs, labels)\n",
    "        \n",
    "        loss.backward()\n",
    "        \n",
    "        optimizer.step()\n",
    "        \n",
    "        total_loss += loss.item()\n",
    "    \n",
    "    return total_loss / len(data_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0be2e40-955d-4303-88eb-5f7c4e432124",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, data_loader, device):\n",
    "    \"\"\"\n",
    "    Evaluates the model on the provided data loader.\n",
    "    Returns accuracy and average loss.\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    correct_predictions = 0\n",
    "    total_predictions = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(data_loader, desc=\"Evaluating\"):\n",
    "            input_ids = batch['input_ids'].to(device)\n",
    "            attention_mask = batch['attention_mask'].to(device)\n",
    "            labels = batch['labels'].to(device)\n",
    "            \n",
    "            outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "            \n",
    "            loss_fn = nn.CrossEntropyLoss()\n",
    "            loss = loss_fn(outputs, labels)\n",
    "            \n",
    "            _, predictions = torch.max(outputs, dim=1)\n",
    "            \n",
    "            total_loss += loss.item()\n",
    "            correct_predictions += torch.sum(predictions == labels)\n",
    "            total_predictions += labels.shape[0]\n",
    "    \n",
    "    # Use float32 instead of double/float64\n",
    "    accuracy = (correct_predictions.float() / total_predictions) * 100  \n",
    "    average_loss = total_loss / len(data_loader)\n",
    "    \n",
    "    return accuracy, average_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67bf8f33-1d77-4a96-82a5-3287330a4869",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Main training loop\n",
    "def train_model(model, train_loader, val_loader, optimizer, device, epochs=3):\n",
    "    \"\"\"\n",
    "    Main training loop that handles the entire training process.\n",
    "    \"\"\"\n",
    "    best_accuracy = 0\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        print(f'\\nEpoch {epoch + 1}/{epochs}')\n",
    "        \n",
    "        # Train one epoch\n",
    "        train_loss = train_epoch(model, train_loader, optimizer, device)\n",
    "        \n",
    "        # Evaluate\n",
    "        val_accuracy, val_loss = evaluate(model, val_loader, device)\n",
    "        \n",
    "        # Print metrics\n",
    "        print(f'Training Loss: {train_loss:.4f}')\n",
    "        print(f'Validation Loss: {val_loss:.4f}')\n",
    "        print(f'Validation Accuracy: {val_accuracy:.4f}')\n",
    "        \n",
    "        # Save best model\n",
    "        if val_accuracy > best_accuracy:\n",
    "            best_accuracy = val_accuracy\n",
    "            # torch.save(model.state_dict(), 'esgbert_model_weights.pt') #saves model's learned parameters (weights)\n",
    "            torch.save(model, \"esgbert_model_full.pth\") #saves full model architecture\n",
    "            print('ESG-BERT model saved!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e4a4be5-5efe-4e17-a3a7-b867ad460d2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# Train the model\n",
    "train_model(model, train_loader, val_loader, optimizer, device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c82ae8e0-e711-4851-94b9-6fb128f48b4a",
   "metadata": {},
   "source": [
    "# Evaluation \n",
    "Check class distribution and use F1-score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db1740a1-4644-4dff-b49a-313b61dcd0a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
    "\n",
    "def evaluate(model, data_loader, device):\n",
    "    \"\"\"\n",
    "    Evaluates the model and returns accuracy, precision, recall, and F1-score.\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    all_labels = []\n",
    "    all_preds = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(data_loader, desc=\"Evaluating\"):\n",
    "            input_ids = batch['input_ids'].to(device)\n",
    "            attention_mask = batch['attention_mask'].to(device)\n",
    "            labels = batch['labels'].to(device)\n",
    "\n",
    "            outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "            _, predictions = torch.max(outputs, dim=1)  # Get predicted class\n",
    "            \n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "            all_preds.extend(predictions.cpu().numpy())\n",
    "\n",
    "    # Compute metrics\n",
    "    accuracy = accuracy_score(all_labels, all_preds)\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(all_labels, all_preds, average='weighted')\n",
    "\n",
    "    print(f'Accuracy: {accuracy:.4f}')\n",
    "    print(f'Precision: {precision:.4f}')\n",
    "    print(f'Recall: {recall:.4f}')\n",
    "    print(f'F1-Score: {f1:.4f}')\n",
    "\n",
    "    return accuracy, precision, recall, f1\n",
    "evaluate(model, val_loader, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "171e29a8-af91-4248-b28c-d928af233d67",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "import numpy as np\n",
    "\n",
    "def evaluate_auc(model, data_loader, device, num_classes=3):\n",
    "    model.eval()\n",
    "    all_labels = []\n",
    "    all_probs = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(data_loader, desc=\"Evaluating\"):\n",
    "            input_ids = batch['input_ids'].to(device)\n",
    "            attention_mask = batch['attention_mask'].to(device)\n",
    "            labels = batch['labels'].to(device)\n",
    "\n",
    "            outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "            probs = torch.nn.functional.softmax(outputs, dim=1)  # Convert logits to probabilities\n",
    "            \n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "            all_probs.extend(probs.cpu().numpy())\n",
    "\n",
    "    auc_score = roc_auc_score(np.eye(num_classes)[all_labels], all_probs, multi_class=\"ovr\")\n",
    "    print(f\"AUC-ROC Score: {auc_score:.4f}\")\n",
    "    return auc_score\n",
    "\n",
    "evaluate_auc(model, val_loader, device, num_classes=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee9ecfb6-3158-4b6a-9721-9a25858def33",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "class_names = [\"Environmental\", \"Social\", \"Governance\"]\n",
    "\n",
    "def evaluate(model, data_loader, device):\n",
    "    \"\"\"\n",
    "    Evaluates the model and returns accuracy, precision, recall, F1-score.\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    all_labels = []\n",
    "    all_preds = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(data_loader, desc=\"Evaluating\"):\n",
    "            input_ids = batch['input_ids'].to(device)\n",
    "            attention_mask = batch['attention_mask'].to(device)\n",
    "            labels = batch['labels'].to(device)\n",
    "\n",
    "            outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "            _, predictions = torch.max(outputs, dim=1)  # Get predicted class\n",
    "            \n",
    "            all_labels.extend(labels.cpu().numpy())  # Convert tensor to numpy\n",
    "            all_preds.extend(predictions.cpu().numpy())\n",
    "\n",
    "    return all_labels, all_preds  # Return both true labels & predictions\n",
    "\n",
    "\n",
    "\n",
    "def plot_confusion_matrix(all_labels, all_preds, class_names):\n",
    "    cm = confusion_matrix(all_labels, all_preds)\n",
    "\n",
    "    plt.figure(figsize=(6, 5))\n",
    "    sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=class_names, yticklabels=class_names)\n",
    "    plt.xlabel(\"Predicted Label\")\n",
    "    plt.ylabel(\"True Label\")\n",
    "    plt.title(\"Confusion Matrix\")\n",
    "    plt.show()\n",
    "\n",
    "all_labels, all_preds = evaluate(model, val_loader, device)\n",
    "plot_confusion_matrix(all_labels, all_preds, class_names)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "(4265_assignment1)",
   "language": "python",
   "name": "4265_assignment1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
